{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Segment Anything Model\n",
    "\n",
    "Imports necessary libraries and sets up variables for loading a pre-trained Segment Anything Model (SAM).\n",
    "Loads the specified SAM model from a checkpoint file and prepares it to run on the selected device (GPU or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from segment_anything import sam_model_registry\n",
    "\n",
    "CHECKPOINT_PATH = 'sam_vit_l_0b3195.pth'\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_TYPE = \"vit_l\"\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
    "sam.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Image\n",
    "\n",
    "Loads an image and prepares it for use with the Segment Anything Model (SAM).\n",
    "Utilizes the SAM model to generate segmentation masks for the loaded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "image_bgr = cv2.imread(\"dog_image.jpg\")\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "result = mask_generator.generate(image_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervision\n",
    "Imports tools for annotation and visualization from the 'supervision' library.\n",
    "Applies the generated segmentations to the image, creating visually annotated output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from supervision.annotators.utils import ColorLookup\n",
    "\n",
    "mask_annotator = sv.MaskAnnotator(color_lookup = ColorLookup.INDEX)\n",
    "detections = sv.Detections.from_sam(result)\n",
    "annotated_image = mask_annotator.annotate(image_bgr, detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Segmentation Mask with Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from segment_anything import SamPredictor\n",
    "import numpy as np\n",
    "\n",
    "mask_predictor = SamPredictor(sam)\n",
    "\n",
    "image_bgr = cv2.imread(\"dog_image.jpg\")\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "mask_predictor.set_image(image_rgb)\n",
    "\n",
    "box = np.array([70, 247, 626, 926])\n",
    "masks, scores, logits = mask_predictor.predict(\n",
    "    box=box,\n",
    "    multimask_output=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export annotated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"annotated_dog_image.jpg\", annotated_image)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
